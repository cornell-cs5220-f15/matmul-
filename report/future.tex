\section{Future work}\label{sec:future}
There are various other optimizations that we did not try which may further
increase the performance of a matrix multiplication kernel.

\begin{itemize}
  \item
    We did not use any explicit vector instructions in our fully optimized
    kernels because the overhead of correctly using explicit vector
    instructions was very high, and we were uncertain if doing so would
    significantly increase the performance of the kennel. In the future, we
    could introduce explicit vector instructions.

  \item
    To multiply two $N \times N$ matrices, all our kernels perform at least
    $N^3$ multiplications and additions. We could implement more sophisticated
    algorithms which reduce the needed number of multiplications. A more
    sophisticated algorithm would likely be more difficult to vectorize making
    it efficient on very large matrices and very inefficient on small and
    modest sized matrices.
\end{itemize}
