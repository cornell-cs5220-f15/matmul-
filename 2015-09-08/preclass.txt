Pre-Class Questions:

Consider the following naive row-based N x N matmul (matrix multiplication):

for (i = 0; i < N; i++){
   for (j = 0; j < N; j++){
      tmp = 0
      for (k = 0; k < N; k++)
         tmp += A[i,k] * B[k,j]
   }
      C[i,j] = tmp
}

Suppose data is in double-precsion floating point. We are interested in
estimating the memory-based arithmetic intensity (AI) of this code. The
memory-based AI is defined that (# flops) / (# bytes transferred between memory
and cache), and depends on the cache size. Suppose the cache uses a
least-recently-used (LRU) policy for deciding which data to flush when moving
something into an already-full cache.

1. Suppose 16N is significantly larger than the size of our L3 cache. What is
the memory-based AI of this code? (Hint: What is the memory-based AI of just the
innermost loop?)


2. Now suppose that the cache is substantially larger than 16N, but
substantially smaller than 8N^2. What is the AI now?


3. Now suppose the cache is large enough to hold all of A, B, and C. What is the
AI now? (Hint: Writing to a byte of memory not already in the cache incurs two
memory transfers: one to move the data to the cache for writing, and one to move
the written data back to main memory.)


4. Cache overflowing. On my CPU (Intel i7-4700 HQ), L1, L2, and L3 caches are 32
KB, 256 KB, and 6 MB respectively. What is the largest problem size N that will
fit in each cache? What is the arithmetic intensity associated with each problem
size?


5. My CPU has 4 cores, each of which can do 8 fused multiply-adds per cycle, has
a clock rate of 2.4 GHz, and a memory bandwidth of 25.6 GB/s. At what arithmetic
intensity does my machine become CPU-bound?


6. So, for what size range for N will naive matmul be CPU-bound on my machine?


7. So, what will a plot of Flops/sec vs N look like?
